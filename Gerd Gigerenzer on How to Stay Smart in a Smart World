This transcript from a 2022 EconTalk episode features a discussion between host Russ Roberts and guest Gerd Gigerenzer. The primary topic is the limitations of Artificial Intelligence (AI), particularly its lack of common sense compared to human intelligence, and the implications of AI's use by tech companies for surveillance and manipulation.

Here's a breakdown of the key statistics and concrete numbers mentioned:

AI vs. Human Learning:

AlphaZero (AI for Chess/Go): Can beat every human, but "doesn't know that there is a game called chess or Go."
Deep Neural Networks (Image Recognition): Need "ten thousands of pictures of school buses" to learn to distinguish them.
Four-year-old human: May need to see a school bus "another time" (e.g., 2 times) to form a concept.
IBM Watson:

Initial claim by IBM CEO (Jeanie Rometty): Watson for healthcare was a "moon chart."
IBM's later clarification: Watson is "at the level of a first-year medical student."
Watson Oncology outcomes: Some recommendations were "dangerously deadly."
Financial Investment Heuristics:

Harry Markowitz's Nobel Prize-winning model: Optimizes diversification into 'n' assets.
Markowitz's personal investment (after retirement): Used a "simple heuristic" called "invest equally" (one over n, e.g., 50/50 for two assets, one-third for three).
Performance of 1/n heuristic: Studies have shown it "often outperforms Markowitz's optimization including modern Bayesian methods" in the real world of finance (unstable world).
Tech Company Business Models (as of 2022):

Google's revenue from advertisement: 80%
Facebook's (Meta's) revenue from advertisement: 97%
Cost of Privacy (Estimated by Gigerenzer):

Per person per month to cover Meta's entire revenue (if users paid for services instead of being the product): Approximately two dollars.
Privacy Paradox in Germany (Gigerenzer's Surveys, latest in 2022):

Percentage of Germans willing to pay nothing for social media to keep their data private: 75%.
Awareness of Smart TV Surveillance (German data):

Percentage of Germans unaware that a smart TV may record personal conversations: 85%.
Digital Understanding in 15-year-olds (PISA Study - International):

Percentage of 15-year-olds who "do not know how to tell facts from fakes": 90%.
Lateral Reading Skills in Undergraduates (Stanford study):

Percentage of young people in Stanford who don't know to check the "about us" section and research who is behind a website to assess trustworthiness: 97%.
YouTube Video Consumption (as of 2022):

Percentage of videos seen that are recommended by algorithms (not chosen by viewers): Some 75%.






what to learn? quotes? explain in simple creative points. ideas


Okay, this is a fun challenge! Let's break down the core ideas of "what to learn?" based on the provided transcript, and then reframe them in simple, creative points and quotes.

What to Learn? (The Transcript's Wisdom Reimagined)
The transcript from the EconTalk discussion with Gerd Gigerenzer offers some profound insights into what truly matters to learn, especially in a world increasingly dominated by algorithms and "smart" technologies. It's not about being a human AI, but about embracing our unique human strengths.

Here's what to learn, explained in simple, creative points:

1. The "Common Sense" Compass üß≠
What to learn: How to develop and trust your intuitive common sense. AI struggles with this, but it's our superpower. It's the silent wisdom that tells you a ball behind a screen isn't gone, or that a deep learning model can beat you at chess but doesn't know what a "game" is.
Why it matters: In an "uncertain world," your common sense is a better guide than a machine's "perfect" calculation.
Creative Point: Think of your brain as a "Common Sense Compass." While AI can calculate precise routes, your compass helps you know if you're even in the right forest.
2. The "Causality Detective" Mind üïµÔ∏è‚Äç‚ôÇÔ∏è
What to learn: To ask "why?" and seek out causal stories, not just correlations. Humans are wired for this; AI is not. We want to understand why something happens, not just that it happens.
Why it matters: Correlations from "big data" are powerful, but they don't explain why things work. In complex, changing environments (like human health or finance), understanding cause and effect is crucial for real insight.
Creative Point: Be a "Causality Detective." While AI can find countless fingerprints (correlations), you're the one asking, "Who actually committed the crime and why?"
3. The "Uncertainty Navigator" Skill üåä
What to learn: How to navigate, and even thrive, in situations of high uncertainty where the future isn't like the past. Algorithms excel in stable, predictable worlds (like games), but falter when things are chaotic or truly novel.
Why it matters: Life, unlike chess, is often full of "calculable risk" (stable) and "uncertainty" (unstable). Our simple heuristics often beat complex algorithms in the latter.
Creative Point: Master the art of being an "Uncertainty Navigator." You're less like a GPS on a highway and more like a seasoned sailor reading unpredictable currents.
4. The "Privacy Protector" Awareness üõ°Ô∏è
What to learn: To be acutely aware of how technology companies (and governments) use your data, and to understand the value of your privacy, even if it feels "free."
Why it matters: The "free coffee house" model means you are the product. Learning about the surveillance economy, the potential for manipulation, and the erosion of trust is vital for maintaining autonomy.
Creative Point: Cultivate your "Privacy Protector" shield. Don't sleepwalk into a world where everything you say and do is recorded and sold.
5. The "Truth Discernment" Superpower ‚ú®
What to learn: How to critically evaluate information, distinguish facts from fakes, and question the source of what you consume online. This includes recognizing confirmation bias and the ease with which we fool ourselves.
Why it matters: In a world flooded with digital content, the ability to discern truth is paramount. It's not about being a "digital native" but a "digitally wise native."
Creative Point: Develop your "Truth Discernment Superpower." It's like having x-ray vision for the internet, seeing through the cool aesthetics and checking the source before believing.
Quotes (Inspired by the Discussion):
On AI's limits:

"AlphaZero can beat every human in chess and Go, but it doesn't know that there is a game called chess or Go."
"A deep neural network is about correlations... nobody has ever talked about multiple regressions as intelligence."
"If the future is not like the past, then big data doesn't help you."
On Human Strengths:

"We are strong in causal stories. We invent, we are looking for 'why, why, why'."
"Another aspect of human intelligence is intuitive psychology... and finally there's an intuitive physics."
"In a world of lots of uncertainty... you need to be very cautious [about algorithm claims]."
"We can do something that [algorithms] cannot do."
On The Surveillance Economy:

"The customer, the user, no longer the customer... we who enjoy our coffee, we are the product being sold."
"It's not about A.I. by itself, it's about the people behind A.I. and their motives."
"What people underestimate is how closely tech companies are interrelated with governments."
On Education & Awareness:

"An important partial solution is make people smart, open their eyes, and make them think about what's happening."
"The first principle is not to fool yourself, and you're the easiest person to fool."





